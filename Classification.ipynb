{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.datasets.mnist as mnist\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/bryan/Documents/sandbox/data/mnist.npz\"\n",
    "debug = True\n",
    "\n",
    "validation_ratio = 0.2\n",
    "lr = 3e-4\n",
    "weight_decay = 0.1\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validation_split_indicies(data_length, val_ratio=0.2):\n",
    "    validation_amount = int(data_length * val_ratio)\n",
    "    p = np.random.choice(range(data_length), data_length, replace=False)\n",
    "    return p[:-validation_amount], p[-validation_amount:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data from MNIST\n",
    "(train_x, train_y), (test_x, test_y) = mnist.load_data(path=data_path)\n",
    "train_idx, valid_idx = get_validation_split_indicies(len(train_x), validation_ratio)\n",
    "\n",
    "validation_x = train_x[valid_idx]\n",
    "validation_y = train_y[valid_idx]\n",
    "\n",
    "train_x = train_x[train_idx]\n",
    "train_y = train_y[train_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "height, width = train_x.shape[1:]\n",
    "hidden_output_size = 100\n",
    "output_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fully_connected(x, output_size, activation=None, name=\"fully_connected\", weight_init=None, bias_init=None):\n",
    "    with tf.variable_scope(name):\n",
    "        w_init = weight_init if weight_init else tf.contrib.layers.xavier_initializer()\n",
    "        b_init = bias_init if bias_init else tf.zeros_initializer()\n",
    "\n",
    "        W = tf.get_variable(\"weight\", shape=[x.shape[1], output_size], initializer=w_init, trainable=True)\n",
    "        b = tf.get_variable(\"bias\", shape=[output_size, ], initializer=b_init, trainable=True)\n",
    "\n",
    "        y = tf.matmul(x, W) + b\n",
    "\n",
    "        if activation:\n",
    "            return activation(y), W, b\n",
    "\n",
    "        return y, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope(\"placeholders\"):\n",
    "    x = tf.placeholder(tf.float32, (None, height, width))\n",
    "    y = tf.placeholder(tf.int64, (None,))\n",
    "\n",
    "with tf.name_scope(\"flatten\"):\n",
    "    flattened_x = tf.reshape(x, (-1, np.product(x.shape[1:])))\n",
    "    \n",
    "with tf.name_scope(\"hidden\"):\n",
    "    sigma, _, _ = fully_connected(flattened_x, hidden_output_size, tf.nn.relu)\n",
    "    \n",
    "with tf.name_scope(\"output\"):\n",
    "    initializer = tf.contrib.layers.xavier_initializer()\n",
    "    W = tf.get_variable(name=\"output_weight\", shape=[hidden_output_size, output_size], \n",
    "                        initializer=tf.contrib.layers.xavier_initializer(), trainable=True)\n",
    "    b = tf.get_variable(name=\"output_bias\", shape=[output_size,], initializer=tf.zeros_initializer(), \n",
    "                        trainable=True)\n",
    "    logits = tf.matmul(sigma, W) + b\n",
    "\n",
    "with tf.name_scope(\"take_max\"):\n",
    "    predictions = tf.argmax(logits, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.sparse_softmax_cross_entropy(y, logits)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(y, predictions), tf.float32))\n",
    "trainer = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"summaries\"):\n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    tf.summary.scalar(\"accuracy\", accuracy)\n",
    "    merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 ==================\n",
      "Training - Loss: 62.41252136230469, Accuracy: 0.2057916671037674\n",
      "Validation - Loss: 58.17912673950195, Accuracy: 0.22550000250339508\n",
      "Epoch: 20 ==================\n",
      "Training - Loss: 31.059356689453125, Accuracy: 0.42664584517478943\n",
      "Validation - Loss: 29.317852020263672, Accuracy: 0.45350000262260437\n",
      "Epoch: 30 ==================\n",
      "Training - Loss: 17.022499084472656, Accuracy: 0.6190208196640015\n",
      "Validation - Loss: 16.820898056030273, Accuracy: 0.6272500157356262\n",
      "Epoch: 40 ==================\n",
      "Training - Loss: 12.452691078186035, Accuracy: 0.7024999856948853\n",
      "Validation - Loss: 12.568055152893066, Accuracy: 0.6977499723434448\n",
      "Epoch: 50 ==================\n",
      "Training - Loss: 9.977433204650879, Accuracy: 0.7503958344459534\n",
      "Validation - Loss: 10.21493911743164, Accuracy: 0.7463333606719971\n",
      "Epoch: 60 ==================\n",
      "Training - Loss: 8.398648262023926, Accuracy: 0.7800208330154419\n",
      "Validation - Loss: 8.750054359436035, Accuracy: 0.7735000252723694\n",
      "Epoch: 70 ==================\n",
      "Training - Loss: 7.355011940002441, Accuracy: 0.7991250157356262\n",
      "Validation - Loss: 7.761330604553223, Accuracy: 0.7927500009536743\n",
      "Epoch: 80 ==================\n",
      "Training - Loss: 6.563025951385498, Accuracy: 0.8132708072662354\n",
      "Validation - Loss: 7.017050743103027, Accuracy: 0.8074166774749756\n",
      "Epoch: 90 ==================\n",
      "Training - Loss: 5.928104400634766, Accuracy: 0.8267291784286499\n",
      "Validation - Loss: 6.4260125160217285, Accuracy: 0.8178333044052124\n",
      "Epoch: 100 ==================\n",
      "Training - Loss: 5.406047344207764, Accuracy: 0.8370624780654907\n",
      "Validation - Loss: 5.9483513832092285, Accuracy: 0.8300833106040955\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    start_time = datetime.now().strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    train_writer = tf.summary.FileWriter(logdir=\"./runs/{}_train\".format(start_time))\n",
    "    validation_writer = tf.summary.FileWriter(logdir=\"./runs/{}_validation\".format(start_time))\n",
    "    sess.run(tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    for epoch in range(epochs):\n",
    "        _, train_summary, train_loss, train_accuracy = sess.run([trainer, merged, loss, accuracy], feed_dict={x: train_x, y: train_y})\n",
    "        train_writer.add_summary(train_summary, epoch)\n",
    "        \n",
    "        validation_summary, validation_loss, validation_accuracy = sess.run([merged, loss, accuracy], feed_dict={x: validation_x, y: validation_y})\n",
    "        validation_writer.add_summary(validation_summary, epoch)       \n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(\"Epoch: {} ==================\".format(epoch + 1))\n",
    "            print(\"Training - Loss: {}, Accuracy: {}\".format(train_loss, train_accuracy))\n",
    "            print(\"Validation - Loss: {}, Accuracy: {}\".format(validation_loss, validation_accuracy))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1560028203.773414"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
